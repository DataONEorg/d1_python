#!/usr/bin/env python

# This work was created by participants in the DataONE project, and is
# jointly copyrighted by participating institutions in DataONE. For
# more information on DataONE, see our web site at http://dataone.org.
#
#   Copyright 2009-2016 DataONE
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Generate the autogenerated restructuredText (reST) files and build the docs.

The d1_python docs are a combination of hand maintained and autogenerated reST (.rst)
files. The autogenerated reST files are built from the docstrings in the Python modules.

This generates the reST files and calls Sphinx to build the HTML and PDF docs from
the reST fies.
"""
import d1_common.utils.progress_tracker
import argparse
import importlib
import os
import pathlib
import pprint
import subprocess
import sys
import pickle

import d1_common.util
import d1_common.utils.ulog
import logging
import d1_common.utils.filesystem
import multiprocessing

# sys.path.append('.')
# noinspection PyUnresolvedReferences
# import source.generate_commands_page

log = logging.getLogger(__name__)

PKG_PATH_LIST = [
    "client_cli/src/d1_cli",
    "client_onedrive/src/d1_onedrive",
    "lib_csw/src/d1_csw",
    "dev_tools/src/d1_dev",
    "gmn/src/d1_gmn",
    "lib_client/src/d1_client",
    "lib_common/src/d1_common",
    "lib_scimeta/src/d1_scimeta",
    "test_utilities/src/d1_test",
    "utilities/src/d1_util",
]

EXCLUDE_LIST = [
    # Exclude all unit and integration tests.
    "**/tests",
    "**/test*.py",
    # Exclude all generated source, like the PyXB bindings.
    "**/types",
    "**/generated",
    "**/migrations",
    # The GMN management commands are handled separately.
    "**/management",
    # Autodoc gets confused about class names when this module is included.
    "**/models",
    # ONEDrive Dokan driver, etc
    "**/drivers",
]

APIDOC_ARG_LIST = ["--module-first", "--doc-project", "API"]

SPHINX_ENV_PICKLE_PATH = 'doc/build/doctrees/environment.pickle'

def main():
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("--rebuild", action="store_true", help="Do a complete rebuild")
    parser.add_argument(
        "--git", action="store_true", help="Stage the new docs for commit (git add)"
    )
    parser.add_argument("--monitor", action='store_true', help="Keep monitoring for changes and build again")
    parser.add_argument("--dump-env", action='store_true', help="Dump the domaindata part of Sphinx's picked env and exit")
    parser.add_argument("--clean", action='store_true', help="Delete all autogenerated .rst files and exit")

    args = parser.parse_args()

    if args.dump_env:
        dump_sphinx_labels()
        return

    makefile_path = d1_common.utils.filesystem.abs_path('.')

    # Configure GMN so that the GMN management commands can be imported.
    # os.environ["DJANGO_SETTINGS_MODULE"] = "d1_gmn.settings_test"
    # django.setup(set_prefix=False)

    d1_python_root_path = d1_common.utils.filesystem.abs_path('../../..')
    os.chdir(d1_python_root_path)
    log.info('CWD: {}'.format(os.getcwd()))

    # wait_for_change()
    # return
    d1_common.utils.ulog.setup(True)

    if args.clean:
        clean_all()
        return

    while True:
        if args.rebuild:
            clean_all()

        build_all(args, makefile_path)

        if not args.monitor:
            break

        wait_for_change()


def clean_all():
    delete_sphinx_pickled_env()
    delete_generated()


def dump_sphinx_labels():
    dat = pickle.load(pathlib.Path(SPHINX_ENV_PICKLE_PATH).open('rb'))
    log.info('Sphinx pickled environment domaindata:')
    pprint.pprint(dat.domaindata)
    # for label, _ in dat.domaindata['std']['labels'].items():
    #     log.info(f'  {label, _}')

def delete_sphinx_pickled_env():
    p = pathlib.Path(SPHINX_ENV_PICKLE_PATH)
    if p.is_file():
        pathlib.Path(SPHINX_ENV_PICKLE_PATH).unlink()
        log.info('Deleted Sphinx pickled env')
    else:
        log.info(f'There is no Sphinx pickled env file at: {p.as_posix()}')


def wait_for_change():
    # "--monitor",
    cmd_list = ["inotifywait", "--quiet", "--recursive", "--format", "%e %w%f", "--event", "modify", "--event", "move", "--event", "create", "--event", "delete", "--exclude", "__pycache__",]
    cmd_list.extend([pathlib.Path(pathlib.Path(v).parts[0]).as_posix() for v in PKG_PATH_LIST])
    # print(cmd_list)
    run_cmd(cmd_list)



def build_all(args, makefile_path):
    log.info('Building...')
    # sphinx-apidoc exclude filters do not work when source path starts with "../", so
    # this script runs with current directory set to the d1_python root, and relative
    # paths must us that as base.
    d1_common.utils.ulog.setup(True)
    log.info('CWD: {}'.format(os.getcwd()))
    gen_command_help = importlib.import_module('d1_doc.gen-command-help')
    gen_command_help.gen_all()

    create_rst_files(args)

    # log.info(sys._getframe(1).f_code.__name__)
    # log.info(os.path.dirname(sys._getframe(1).f_code.co_filename))
    # log.info('Makefile path: {}'.format(makefile_path))

    log.info('CWD: {}'.format(os.getcwd()))
    log.info(f'{"#"*100}')
    log.info(f'Building HTML with sphinx-build. Can take a while...')
    # sphinx-build is set to launch its own processes via "-j auto" in the Makefile.
    run_cmd("make", "-C", makefile_path, "html")

    if args.git:
        git_add()


def create_rst_files(args):
    """Look recursively in <MODULE_PATH> for Python modules and packages and create one
    reST file with automodule directives per package in the <OUTPUT_PATH>. The
    <EXCLUDE_PATTERN>s can be file and/or directory patterns that will be excluded from
    generation. Note: By default this script will not overwrite already created files.
    """
    apidoc_arg_list = APIDOC_ARG_LIST.copy()

    if args.rebuild:
        apidoc_arg_list.append("--force")

    pool = multiprocessing.Pool(10)

    result_list = []

    for pkg_path in PKG_PATH_LIST:
        pkg_name = pkg_path.split("/")[-1]
        api_path = f"./doc/rst/{pkg_name}/api/"
        # log.info('Current dir: {}'.format(os.getcwd()))
        log.info('Creating .rst for: {}'.format(pkg_path))

        arg_tup = tuple(apidoc_arg_list + ["-o", api_path, pkg_path] + EXCLUDE_LIST)
        result_list.append(pool.apply_async(launch_sphinx_apidoc, args=(arg_tup,)))

        #  ['sphinx-apidoc', '--module-first', '--doc-project', 'API', '--force', '-o', './doc/rst/d1_common/api/', 'lib_common/src/d1_common', '**/tests', '**/test*.py', '**/generated', '**/migrations', '**/management', '**/models', '**/drivers']
        # run_cmd(
        #     "sphinx-apidoc", apidoc_arg_list, "-o", api_path, pkg_path, EXCLUDE_LIST
        # )

    for result in result_list:
        log.info(result.get())


    pool.close()
    pool.join()


def launch_sphinx_apidoc(arg_list):
    log.info(f'Starting process: sphinx-apidoc {cmd_list_to_str(arg_list)}')
    return run_cmd("sphinx-apidoc", list(arg_list))


def git_add():
    for pkg_path in PKG_PATH_LIST:
        root_name = pkg_path.split("/")[0]
        doc_path = f"{root_name}/doc/api"
        run_cmd("git", "add", doc_path)


def delete_generated():
    """Force a complete rebuild of the documentation. This is often necessary in order
    to pick up changes after deleting or renaming modules.
    """
    run_cmd(
        "find", "-L", "./doc/rst", "-type", "f", "-wholename", "*/api/*", "-delete"
    )
    run_cmd(
        "find", "-L", "./doc/rst", "-type", "f", "-name", "commands_generated.rst", "-delete"
    )

def cmd_list_to_str(cmd_list):
    return ' '.join([f'"{v}"' for v in cmd_list ])

def run_cmd(*cmd_list):
    flat_list = []
    for cmd in cmd_list:
        if isinstance(cmd, list):
            flat_list.extend(cmd)
        else:
            flat_list.append(cmd)

    log.info("Running command: {}".format(flat_list))
    # log.info("Running command: {}".format(" ".join(flat_list)))
    try:
        # subprocess.Popen(flat_list)
        return subprocess.check_output(flat_list)
    except subprocess.CalledProcessError as e:
        log.error("Failed: {}".format(str(e)))


if __name__ == "__main__":
    sys.exit(main())
